\chapter{Expansion Algorithms}\label{chapter:algorithms}
In the following chapter different approaches for generating small expansion sets $S$ as well as the edge expansion of hypergraphs are discussed.
%TODO: NP-hard? --> approximation needed
%todo: which tense to use where?



\section{Brute Force}
One obvious approach for generating the edge expansion $\Phi(H)$ of a hypergraph $H$ is to brute-force the problem like in \cref{alg:brute_force}.
\begin{algorithm}[H]
	\caption{Brute-force edge expansion on a hypergraph \label{alg:brute_force}}
	\begin{algorithmic}
		\Function{BruteForceEdgeExpansion}{$H := (V,E, w)$}
		\State $best\_S := null$
		\State $lowest\_expansion := \infty$
		\For{$\emptyset \neq S \subsetneq V$}
		\State $expansion :=  \max\{ \Phi(S), \Phi({V\setminus S})\}$
		\If{$expansion < lowest\_expansion$}
			\State $lowest\_expansion := expansion$
			\State $best\_S := S$
		\EndIf
		\EndFor	
		\State return $best\_S$
		\EndFunction
	\end{algorithmic}
\end{algorithm}


As \cref{alg:brute_force} iterates over all the possible subsets $\emptyset \neq S \subsetneq V$, it computes \begin{equation}
\arg\min_{\emptyset \subsetneq S \subsetneq V} \max{( \Phi(S), \Phi({V\setminus S}))} = \Phi(H).
\end{equation}

There are $2^{|V|}-2 = 2^{n}-2 \in O(2^n) $ combinations for $\emptyset \neq S \subsetneq V$, namely all the $2^{|V|}$ subsets of $V$ excluding the empty set $\emptyset$ and $V$ itself. Hence, this algorithm is of exponential time complexity in $n$ and is therefore not efficient for larger graphs as evaluated in \cref{fig:no_vertices_time}.
%TODO: In fact the problem is  unique games conjecture, np-hard

For the purpose of analyzing the graph creation algorithms in \cref{chapter:random_hypergraphs}, it can be insightful to observe the lowest expansion of each possible size (in the number of vertices) like in \cref{alg:brute_force_size}.

\begin{algorithm}[H]
	\caption{Brute-force edge expansion of a hypergraph for every size   \label{alg:brute_force_size}}
	\begin{algorithmic}
		\Function{BruteForceEdgeExpansionSizes}{$H := (V,E, w)$}
		\State $best\_S\_of\_size := \{\}$
		\State $lowest\_expansion\_of\_size := \{1:\infty, 2:\infty, \ldots, n-1: \infty \}$
		\For{$\emptyset \neq S \subsetneq V$}
		\State $expansion := \max{ \Phi(S), \Phi({V\setminus S})}$
		\If{$expansion < lowest\_expansion\_of\_size[|S|]$}
		\State $ lowest\_expansion\_of\_size[|S|] := expansion$
		\State $best\_S\_of\_size[|S|] := S$
		\EndIf
		\EndFor	
		\State return $best\_S\_of\_size$
		\EndFunction
	\end{algorithmic}
\end{algorithm}


In order to analyze the results from \cref{alg:ses}, which only computes $\Phi(S)$, the expansion of a set $S$, not the whole graph, it makes sense to compare it with the best result possible for the same size of $S$. Therefore, just the line for the computation of the expansion \cref{alg:brute_force_size} needs to be changed to get \cref{alg:brute_force_size_just_one_side}.

\begin{algorithm}[H]
	\caption{Brute-force edge expansion of sets for every size   \label{alg:brute_force_size_just_one_side}}
	\begin{algorithmic}
		\Function{BruteForceEdgeExpansionSizes}{$H := (V,E, w)$}
		\State $best\_S_of_size := \{\}$
		\State $lowest\_expansion\_of\_size := \{1:\infty, 2:\infty, \ldots, n-1: \infty \}$
		\For{$\emptyset \neq S \subsetneq V$}
		\State $expansion :=  \Phi(S)$
		\If{$expansion < lowest\_expansion\_of\_size[|S|]$}
		\State $ lowest\_expansion\_of\_size[|S|] := expansion$
		\State $best\_S\_of\_size[|S|] := S$
		\EndIf
		\EndFor	
		\State return $best\_S\_of\_size$
		\EndFunction
	\end{algorithmic}
\end{algorithm}
For \cref{alg:brute_force_size} and \cref{alg:brute_force_size_just_one_side} the above argument of for exponential complexity holds as well.

\section{Approximation of small expansion sets}
As described in \cite{ChanLTZ16}, an algorthm for generating a random small expansion set can be derived. 


For a given Graph $H$ we can find a small expansion set with \cref{alg:ses}, where $k \ge 2$ is an integer.



\begin{algorithm}[htpb]
	\caption{Find Small Expansion Set \label{alg:ses}} 
	\begin{algorithmic}
		\Function{SmallExpansionSet}{$H, k$}
		\State $f_1 \ldots, f_k := $\Call{SampleSmallVectors}{$H, k$}
		\State return \Call{SmallSetExpansion}{$H, f_1 \ldots, f_k$}
		\EndFunction 
	\end{algorithmic}
\end{algorithm}	

In the main algorithm, the first call to \cref{alg:procedural_minimizer}, returns a set of orthonormal vectors $\{f_1, \ldots, f_k\}$, where each vector $f_i \in \mathbb{R}^V$ gives a value to each vertex. Because of \cref{fact:small_xi} it is of importance for \cref{alg:small_set_expansion} that  $\xi := \max_{s \in [k]} D_w(f_s)$ is small. 
At first, $f_1$ is set to be $\frac{\vec{1}}{||\vec{1}||_w}$. Following that, the other vectors $f_2, \ldots, f_k$ are sampled after another, using \cref{alg:sample_random_vector}. This sampling of vectors after another where the discrepancy ratio of the next vector shall be minimal is also referred to as procedural minimizers. In this way an approximation for the ideal vectors, which achieve $\xi_k$ as defined in \cref{eq:xi} is achieved.


 
\begin{algorithm}[htpb]
	\caption{Procedural Minimizer \label{alg:procedural_minimizer}} 
	\begin{algorithmic}
		\Function{SampleSmallVectors}{$H,k$}
		\State $f_:1= \frac{\vec{1}}{||\vec{1}||_w}$
		
		\For{$i = 2, \ldots, k$}
		\State $f_i := $\Call{SampleRandomVector}{$H, f_1, \ldots, f_{i-1}$}
		\EndFor
		\State return $f_1, \ldots , f_k$
		\EndFunction 
	\end{algorithmic}
\end{algorithm}	

\begin{sdp}{SDP for minimizing $g$, (SDP 8.3 in \cite{ChanLTZ16}) \label{SDP}} %todo: better name, where from
	\begin{mini*}
		{g}{\text{SDPval} := \sum_{e\in E} w_e \max_{u,v\in e} ||\vec{g_u} -\vec{g_v} ||^2}{}{}
		\addConstraint{ \sum_{u\in V} w_v ||\vec{g_v}||^2 }{= 1}{}
		\addConstraint{ \sum_{u\in V} w_v f_i(v)  \vec{g_v} }{=\vec{0},\quad}{\forall i \in [k-1]}
	\end{mini*}
\end{sdp}


In \cref{alg:sample_random_vector}, SDP \ref{SDP} is solved in order to generate vectors $\vec{g_v} \in \mathbb{R}^n $ for $v \in V$. The idea behind the vector $\vec{g_v}$ is to represent the coordinate $v$ in the next vector $f$, which is being created. Therefore, $\vec{g_v} $ in the SDP relates to $f_v $ in the discrepancy ratio defined in \cref{eq:discrepancy_ratio}. The first constraint limits the norm of the vector whilst the following ensure orthonormality to the already existing vectors. By sampling a vector from a gaussian and multiplying it with all the $\vec{g_v}$, the coordinates of $f$ are created. According to fact \ref{fact:small_discrepancy_ratio}, the maximal discrepancy ratio $ \max_{s \in [k]} D_w(f_s)$, among the vectors which are returned by \cref{alg:sample_random_vector}, is small with high probability. Therefore, in the implementation of \cref{alg:sample_random_vector}, the steps after solving the SDP are repeated several times and the $f$ with the smallest $D_w(f)$ is returned.

\begin{fact}{(Theorem 8.1 in \cite{ChanLTZ16}) \label{fact:small_discrepancy_ratio}}
There exists a randomized polynomial time algorithm that, given a hypergraph $H = (V,E,w)$ and a parameter $ k < |V |$, outputs $k$ orthonormal vectors $f_1, \ldots , f_k$ in the weighted space such that with high probability, for each $i  \in [k],$
\begin{equation}
	D_w(f_i) \le \mathcal{O} (i \xi_i \log r  ) .
\end{equation}	
\end{fact}

\begin{algorithm}[htpb]
	\caption{Sample Random Vector (Algorithm 3 in \cite{ChanLTZ16}) \label{alg:sample_random_vector}} 
	\begin{algorithmic}
		\Function{SampleRandomVector}{$H, f_1, \ldots, f_{i-k}$}
		\State Solve SDP \ref{SDP} to generate vectors $\vec{g_v} \in \mathbb{R}^n $ for $v \in V$
		\State $\vec{z} := sample(\mathcal{N}(0,I_n))$
		\For{$v\in V $}
		\State $f(v) := <\vec{g_v}, \vec{z}>$
		\EndFor
		\State return $f$
		\EndFunction 
	\end{algorithmic}
\end{algorithm}	

After sampling of the vectors $f_1, \ldots, f_k$, \cref{alg:ses} calls \cref{alg:small_set_expansion}. There the vectors $f_1 , \ldots , f_k$ are flipped to form $u_v$. Each $u_v$ represents the $f$-values for a vector $v\in V$.
After normalizing each $u_i$ to $\tilde{u}_i $, they are handed over to \cref{alg:orthogonal_separator}, which returns a subset of the $\tilde{u}_v$s. With this subset, a vector $X$ is constructed. $X_i$  takes the value $||u_v||$ if $\tilde{u}_v \in \hat{S} $, otherwise $0$. Then, $X$ is sorted in decreasing order. 
Afterwards all the prefixes of $X$ are analyzed for the expansion of their respecting vertices. The set of vertices $S$ with the lowest expansion is returned.




\begin{algorithm}[H]
	\caption{Small Set Expansion (according to Algorithm 1 in \cite{ChanLTZ16}) \label{alg:small_set_expansion}} %todo: better name
	
	
	\begin{algorithmic}
		\Function{SmallSetExpansion}{$G := (V,E, w), f_1, \ldots , f_k$}
		\State assert $\xi == \max_{s\in [k]} \{D_w(f_s)\}$
		\State assert $\forall f_i, f_j \in \{f_1, \ldots , f_k\} \subset \mathbb{R}^n, i\neq j: f_i \text{ and } f_j \text{ orthonormal in weighted space} $
		
		\For{$v \in V$}
		\For{$s\in [k]$}
		\State	$u_v(s) := f_s(v) $
		\EndFor
		\EndFor
		
		\For{$v \in V$}
		\State $\tilde{u}_v := \frac{u_v}{||u_v||}$
		\EndFor
		
		\State $\hat{S} := $ \Call{OrthogonalSeparator}{$\{\tilde{u}_v\}_{v\in V} , \beta = \frac{99}{100}, \tau = k$ }
		
		\For {$i \in S$}
		\If {$\tilde{u}_v \in \hat{S}$ }

		\State $X_v := ||u_v||^2$
		\Else
		\State $X_v := 0$
		\EndIf
		
		\EndFor
		\State $X:= $ sort $ list(\{X_v\}_{v \in V})$
		\State $V := [v]_{\text{in order of X}}$
		\State $S := \arg \min_{\{P \text{ is prefix of }V\}}\phi(P)$
		
		\State return $S$
		
	
	
		\EndFunction
		
		
	\end{algorithmic}
\end{algorithm} %todo: explain list syntax in notation


In \cref{alg:orthogonal_separator} a number of $l := \lceil \frac{\log_2 k}{1-\log_2 k}\rceil$ assignments are sampled for each vertex $u \in V$ with the help of \cref{alg:sample_assignments}. Assignment $j \in [l]$ assigns a value $w_j(u) \in \{0,1\}$ to each vertex $u$. With that, for each vertex $u$, a word $W(u) =  w_1(u)w_2(u)\cdots w_l(u)$ can be defined. Then a random word is picked, depending on the size of $n$ and $2^l$, either from $\{0,1\}^l$ or from all the constructed words with the same probability. In this case, $|V|-\# \text{distinct words in }W$ are constructed and added to the set of words to pick from. Following, a value $r\in(0,1)$ is chosen uniformly at random. Only those vertices $v$ whose word $W(v)$ equals the chosen $word$ and whose vector $\tilde{u}_v$ is smaller than $r$ get selected into the set $S$ which is returned to \cref{alg:small_set_expansion}.

\begin{algorithm}[htpb]
	\caption{Orthogonal Separator (combination of Lemma 18 and algorithm Theorem 10 in \cite{LouisM14} (also Fact 6.7 in \cite{ChanLTZ16})) \label{alg:orthogonal_separator}} 
\begin{algorithmic}
	\Function{OrthogonalSeparator}{$\{\tilde{u}_v\}_{v\in V} , \beta = \frac{99}{100}, \tau = k$}
	\State $l := \lceil \frac{\log_2 k}{1-\log_2 k}\rceil$


	
	\State $w := $\Call{SampleAssignments}{$l, V, \beta$}
	
	\For{$ v \in V$}
	\State $W(u) := w_1(v)w_2(v)\cdots w_l(v)$
	\EndFor
	
	\If{$n\ge 2^l$}
	\State $word := random( \{0,1\}^l)$ \Comment uniform
	
	\Else
	 
	\State $words := set({w(v): v\in V})$ \Comment no multiset
	\State $words = words \uplus \{w_1, \ldots , w_{|V|-|words|} \in \{0,1\}^l\} $ 
	\State $word := random(words)$ \Comment uniform
	
	\EndIf
	
	\State $r := uniform(0,1)$
	\State $S := \{v \in V: ||u_v||^2 \ge r \land W(u) = word \}$
	\State return $S$
	
	\EndFunction %todo: 1-vector explain;
	%todo: explain norm
	%todo: i or u or v for what?
\end{algorithmic}
\end{algorithm}	

For sampling the assignments \cref{alg:sample_assignments} uses a Poisson process on $\mathbb{R}$ with rate $\lambda$. It is important to note that for one call of the algorithm, the times on which the events happen do not change. Therefore, given a time $t$, the process returns the number of events which have happened between $t_0 = 0$ and $t$. Observe that $t\in \mathbb{R}$ can also take negative values.
Additionally, a vector $g \in \mathbb{R}^n$ is sampled where each component is sampled independently from $\mathcal{N}(0,1)$. Then for each vertex $v$ and for $i = 1, 2, \ldots, l$ a 'time' $t = \langle g, \tilde{u}_v \rangle $ is calculated. Depending on whether the number of events happened in the Poisson process until $t$, is even or odd, $w_i(v)$ is set to $0$ or $1$. Finally, $w$ is returned.
	
\begin{algorithm}[htpb]
	\caption{Sample Assignments (proof of Lemma 18 in \cite{LouisM14}) \label{alg:sample_assignments}} 
	\begin{algorithmic}
	\Function{SampleAssignments}{$l, V, \beta$}
		\State $\lambda := \frac{1}{\sqrt{\beta}}$
			\State $g:=$ sample($\mathcal{N}(0,I_n)$) \Comment all components $g_i$ are mutually independent 
	
	\State $poisson\_process := N(\lambda)$ \Comment N is a Poisson process on $\mathbb{R}$ with rate $\lambda$
		 
	\For {$i = 1, 2, \ldots, l$}
	\For{$v\in V$}
	
	
	\State $t := \langle g, \tilde{u}_v \rangle $
	\State $poisson\_count := poisson\_process(t)$ \Comment \# events between $t=0$ and $t_v$
	\If{$poisson\_count \mod 2 == 0 $}
	\State $w_i(v) := 1$
	\Else
	\State  $w_i(v) := 0$
	\EndIf
	\EndFor
	\EndFor
	\State return $w$
	\EndFunction %todo: 1-vector explain
\end{algorithmic}
\end{algorithm}	
\begin{fact}{(Theorem 6.6 in \cite{ChanLTZ16})}\label{fact:small_xi}
	Given a hypergraph $H = (V, E, w)$ and $k$ vectors $f_1, f_2, \ldots , f_k$ which are orthonormal in the weighted space with $ \max_{s \in [k]} D_w(f_s) \le \xi $, the following holds: Algorithm \ref{alg:small_set_expansion} constructs a random set $S \subsetneq V$ in polynomial time such that with $\Omega(1)$ probability, $|S| \le \frac{24|V|}{k}$ and
	 \begin{equation}\label{eq:small_expansion}
	 \phi(S) \le C \min\{\sqrt{r \log k}, k \log k  \log \log k \sqrt{\log r} \} \cdot \sqrt{\xi},
	 \end{equation}
	 where $C$ is an absolute constant and $r := \max_{e\in E} |e|$.
\end{fact}



Todo: this makes use of the spectral properties... Rayleigh, laplacian, cheeger, 






%todo: Algorithm instead of algorithm at sentence-beginning
%todo: formatting

